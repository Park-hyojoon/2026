현재 amir-learning-planner 프로젝트의 'English speaking' (AI 영어 코치) 기능에 연결된 AI 방식은 다음과 같습니다.

1. 음성 관련 (Speaking & Listening)
별도의 유료 클라우드 AI(예: Google Cloud Speech 등)를 쓰지 않고, **브라우저 내장 기술(Web Speech API)**을 활용하고 있습니다.

음성 인식 (STT): 브라우저의 webkitSpeechRecognition 인터페이스를 호출하여 사용자의 마이크 입력을 텍스트로 변환합니다.
음성 합성 (TTS): 브라우저의 speechSynthesis 기능을 사용하여 AI의 답변을 영어 음성으로 읽어줍니다.
2. 대화 및 학습 로직 (AI Tutor Logic)
현재 파일(
EnglishCoach.jsx
)을 확인한 결과, 외부 LLM(OpenAI, Ollama 등)을 API로 직접 연결한 상태가 아니라 '규칙 기반의 지능형 시뮬레이션(Mock-up)' 방식으로 작동하고 있습니다.

집착 학습(Obsessive Learning) 알고리즘: 사용자가 등록한 'Golden Phrases(핵심 표현)'를 대화 중에 사용했는지 실시간으로 체크합니다.
사용했을 때: "Excellent! You used..."라며 긍정적인 피드백을 줍니다.
사용하지 않았을 때: 미리 준비된 5가지 유도 질문(Elicitation Prompts) 중 하나를 무작위로 골라, 사용자가 해당 표현을 반드시 쓰도록 집요하게 질문을 던집니다. (예: "Interesting! By the way, how would you [핵심표현] in your work?")
3. 왜 이렇게 구성되어 있나요?
이전 개발 단계에서의 
구현 계획서(implementation_plan.md)
에 따르면, 다음과 같은 전략을 취하고 있습니다.

비용 절감: 매번 유료 API를 호출하지 않고도 브라우저 내장 기능만으로 "말하고 듣는" 환경을 구축했습니다.
학습 효율: 단순한 일상 대화보다는 사용자가 외우고자 하는 특정 표현을 무조건 입 밖으로 내뱉게 만드는 것에 초점을 맞춘 'Amir 전용 학습 엔진'을 우선 적용한 상태입니다.
요약하자면: 현재는 브라우저 내장 음성 AI와 특수 설계된 유도 알고리즘이 결합된 형태이며, 추후 사용자의 필요에 따라 Ollama나 OpenAI를 연동하여 '자유 대화' 기능을 확장할 수 있는 준비가 되어 있는 상태입니다.